{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"distilbert (1).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3.6.9 64-bit ('py36': conda)","language":"python","name":"python369jvsc74a57bd047a2385e02337c9da7f7e3138ce6736e525632c23d10436a8fc6b989d8de9769"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0ee175a","executionInfo":{"status":"ok","timestamp":1627835763471,"user_tz":-330,"elapsed":3740,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}},"outputId":"74ba9f10-f46e-4b6a-f417-9e1114b2c719"},"source":["!pip install transformers\n"],"id":"b0ee175a","execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s6FiV0enfQJ4","executionInfo":{"status":"ok","timestamp":1627835766311,"user_tz":-330,"elapsed":2847,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":["import pandas as pd\n","import torch\n","from sklearn.model_selection import train_test_split\n","import transformers\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import DistilBertModel, DistilBertTokenizer\n","from sklearn import metrics\n","from tqdm import tqdm\n","import numpy as np"],"id":"s6FiV0enfQJ4","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"4a493865","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1627835766317,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}},"outputId":"69ad4aee-51e8-4b0a-890b-534ee40f43e4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","train_data = pd.read_csv(\"/content/drive/MyDrive/airline_sentiment_analysis.csv\").dropna()\n","train_data.head()\n"],"id":"4a493865","execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>airline_sentiment</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>positive</td>\n","      <td>@VirginAmerica plus you've added commercials t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>negative</td>\n","      <td>@VirginAmerica it's really aggressive to blast...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>negative</td>\n","      <td>@VirginAmerica and it's a really big bad thing...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>negative</td>\n","      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>positive</td>\n","      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  ...                                               text\n","0           1  ...  @VirginAmerica plus you've added commercials t...\n","1           3  ...  @VirginAmerica it's really aggressive to blast...\n","2           4  ...  @VirginAmerica and it's a really big bad thing...\n","3           5  ...  @VirginAmerica seriously would pay $30 a fligh...\n","4           6  ...  @VirginAmerica yes, nearly every time I fly VX...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"i8Bd0BjYz9Rd","executionInfo":{"status":"ok","timestamp":1627835766318,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":[""],"id":"i8Bd0BjYz9Rd","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5d12be20","executionInfo":{"status":"ok","timestamp":1627835774052,"user_tz":-330,"elapsed":7742,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}},"outputId":"b6e3037d-7f57-4889-fb24-5dbc1ec4cf22"},"source":["import re\n","!pip install emoji\n","import emoji\n","def process_tweet(tweet):\n","    new_tweet = tweet.lower()\n","    new_tweet = re.sub(r'@\\w+', '', new_tweet) # Remove @s\n","    new_tweet = re.sub(r'#', '', new_tweet) # Remove hashtags\n","    new_tweet = re.sub(r':', ' ', emoji.demojize(new_tweet)) # Turn emojis into words\n","    new_tweet = re.sub(r'http\\S+', '',new_tweet) # Remove URLs\n","    new_tweet = re.sub(r'\\$\\S+', 'dollar', new_tweet) # Change dollar amounts to dollar\n","    new_tweet = re.sub(r'[^a-z0-9\\s]', '', new_tweet) # Remove punctuation\n","    new_tweet = re.sub(r'[0-9]+', 'number', new_tweet) # Change number values to number\n","    return new_tweet\n","\n","def binary(sentiment):\n","  if sentiment == \"positive\":\n","    return 1\n","  else:\n","    return 0 \n","train_data[\"text\"] = train_data[\"text\"].apply(process_tweet)\n","train_data[\"airline_sentiment\"] = train_data[\"airline_sentiment\"].apply(binary)\n"],"id":"5d12be20","execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.4.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"5B4sJy2WJ3Su","executionInfo":{"status":"ok","timestamp":1627835774056,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}},"outputId":"2bfd4014-f946-4443-e835-6696ad148045"},"source":["train_data.head()"],"id":"5B4sJy2WJ3Su","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>airline_sentiment</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>plus youve added commercials to the experienc...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>its really aggressive to blast obnoxious ente...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>and its a really big bad thing about it</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>seriously would pay dollar a flight for seats...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>yes nearly every time i fly vx this ear worm ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  ...                                               text\n","0           1  ...   plus youve added commercials to the experienc...\n","1           3  ...   its really aggressive to blast obnoxious ente...\n","2           4  ...            and its a really big bad thing about it\n","3           5  ...   seriously would pay dollar a flight for seats...\n","4           6  ...   yes nearly every time i fly vx this ear worm ...\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"aMo0Yw7Il_Je","executionInfo":{"status":"ok","timestamp":1627835774057,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":["train_data = train_data.drop(train_data.columns[0], axis=1)"],"id":"aMo0Yw7Il_Je","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ed784797","executionInfo":{"status":"ok","timestamp":1627835774057,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":["#train_data , test_data = train_test_split(train_data,test_size=0.1)\n","#train_data.head()"],"id":"ed784797","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"25de7212","executionInfo":{"status":"ok","timestamp":1627835774058,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":["#test_data.head()"],"id":"25de7212","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5c47a14e","executionInfo":{"status":"ok","timestamp":1627835776480,"user_tz":-330,"elapsed":2429,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}},"outputId":"412c1dc6-8aac-4d29-82a3-7fbf6af22612"},"source":["tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n","\n","model, pretrained_weights = (transformers.DistilBertModel, 'distilbert-base-uncased')\n","model = model.from_pretrained(pretrained_weights)\n","\n","#for child in model.children():\n","#  for param in child.parameters():\n","#      param.requires_grad = False"],"id":"5c47a14e","execution_count":9,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a556f82d","executionInfo":{"status":"ok","timestamp":1627835776480,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}},"outputId":"fa8af2b3-b346-41e8-858a-27776d3acab6"},"source":["print(' Original: ', train_data[\"text\"][1])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(train_data[\"text\"][1]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_data[\"text\"][1])))"],"id":"a556f82d","execution_count":10,"outputs":[{"output_type":"stream","text":[" Original:   its really aggressive to blast obnoxious entertainment in your guests faces amp they have little recourse\n","Tokenized:  ['its', 'really', 'aggressive', 'to', 'blast', 'ob', '##no', '##xious', 'entertainment', 'in', 'your', 'guests', 'faces', 'amp', 'they', 'have', 'little', 'rec', '##ours', '##e']\n","Token IDs:  [2049, 2428, 9376, 2000, 8479, 27885, 3630, 25171, 4024, 1999, 2115, 6368, 5344, 23713, 2027, 2031, 2210, 28667, 22957, 2063]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e87aafb8","executionInfo":{"status":"ok","timestamp":1627835776481,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":["#x_token = x_train.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)[:300]))\n","\n","#padded = np.array([i + [0]*(300 -len(i)) for i in x_token.values])"],"id":"e87aafb8","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"4e607ddb","executionInfo":{"status":"ok","timestamp":1627835776482,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":["#attention_mask = np.where(padded != 0, 1, 0)\n"],"id":"4e607ddb","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6dfbe5b","executionInfo":{"status":"ok","timestamp":1627835776483,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":[""],"id":"d6dfbe5b","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"b5adfebf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627835776484,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}},"outputId":"81306b01-bfe0-438a-ecab-2c04545354af"},"source":["class tweet_Dataset(torch.utils.data.Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        \n","    def __getitem__(self, index):\n","        review = str(self.data[\"text\"][index])\n","        inputs = self.tokenizer.encode_plus(\n","            review,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            truncation = True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'targets': torch.tensor(self.data[\"airline_sentiment\"][index], dtype=torch.long)\n","        }\n","        \n","    def __len__(self):\n","        return len(self.data)\n","  \n","train_dataset = tweet_Dataset(train_data, tokenizer,100)\n","\n","train_dataset , test_dataset = torch.utils.data.random_split(train_dataset, [10541, 1000])\n","print(len(train_dataset))\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True,drop_last = True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True,drop_last = True)\n"],"id":"b5adfebf","execution_count":13,"outputs":[{"output_type":"stream","text":["10541\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3f675d60","executionInfo":{"status":"ok","timestamp":1627835778805,"user_tz":-330,"elapsed":2330,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}},"outputId":"0c51d356-9447-4309-a903-06ce2a983882"},"source":["class DistillBERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.distill_bert = model\n","        self.drop = torch.nn.Dropout(0.1)\n","        self.out = torch.nn.Linear(768, 2)\n","    \n","    def forward(self, ids, mask):\n","        distilbert_output = self.distill_bert(ids, mask)\n","        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n","        pooled_output = hidden_state[:, 0]  # (bs, dim)\n","        output_1 = self.drop(pooled_output)\n","        output = self.out(output_1)\n","        return output\n","    \n","model = DistillBERTClass()\n","model.to(device)"],"id":"3f675d60","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DistillBERTClass(\n","  (distill_bert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (drop): Dropout(p=0.1, inplace=False)\n","  (out): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"e703f603","executionInfo":{"status":"ok","timestamp":1627835778805,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"],"id":"e703f603","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"WQ7a2Xq9khl8","executionInfo":{"status":"ok","timestamp":1627835778806,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":["def accuracy(y_pred, y):\n","    _, predicted = torch.max(torch.sigmoid(y_pred).data, 1)\n","    total = y.size(0)\n","    correct = (predicted == y).sum().item()\n","    return correct\n"],"id":"WQ7a2Xq9khl8","execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cb0894e","executionInfo":{"status":"ok","timestamp":1627836131386,"user_tz":-330,"elapsed":352585,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}},"outputId":"fd0e5e62-f621-495b-e723-b00610a2a0b0"},"source":["\n","for epoch in range(2):\n","    acc = 0\n","    for i,data in enumerate(train_loader,0):\n","        optimizer.zero_grad()\n","        input_ids = data['ids'].to(device)\n","        attention_mask = data['mask'].to(device)\n","        labels = data['targets'].to(device)\n","        outputs = model(input_ids,attention_mask)\n","        #loss = nn.functional.binary_cross_entropy(nn.functional.sigmoid(outputs), labels)\n","        loss = loss_fn(outputs,labels)\n","        loss.backward()\n","        optimizer.step()\n","        acc += accuracy(outputs,labels)\n","        if i%50 == 49:\n","            print('[%d, %d] accuracy: %.3f' %\n","                  (epoch + 1, i + 1, acc / ((i+1)*16)))\n","\n","\n","\n"],"id":"2cb0894e","execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["[1, 50] accuracy: 0.770\n","[1, 100] accuracy: 0.801\n","[1, 150] accuracy: 0.798\n","[1, 200] accuracy: 0.805\n","[1, 250] accuracy: 0.814\n","[1, 300] accuracy: 0.829\n","[1, 350] accuracy: 0.839\n","[1, 400] accuracy: 0.849\n","[1, 450] accuracy: 0.857\n","[1, 500] accuracy: 0.863\n","[1, 550] accuracy: 0.868\n","[1, 600] accuracy: 0.872\n","[1, 650] accuracy: 0.876\n","[2, 50] accuracy: 0.917\n","[2, 100] accuracy: 0.924\n","[2, 150] accuracy: 0.923\n","[2, 200] accuracy: 0.924\n","[2, 250] accuracy: 0.926\n","[2, 300] accuracy: 0.929\n","[2, 350] accuracy: 0.928\n","[2, 400] accuracy: 0.930\n","[2, 450] accuracy: 0.929\n","[2, 500] accuracy: 0.932\n","[2, 550] accuracy: 0.931\n","[2, 600] accuracy: 0.932\n","[2, 650] accuracy: 0.932\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s3HFNGc9mcCO","executionInfo":{"status":"ok","timestamp":1627836132005,"user_tz":-330,"elapsed":624,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":["torch.save(model, \"weights.pth\")"],"id":"s3HFNGc9mcCO","execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"9f735122","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627836138471,"user_tz":-330,"elapsed":6469,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}},"outputId":"76b421b4-6b8c-4335-f432-a8e1e452075a"},"source":["\n","acc = 0\n","with torch.no_grad():\n","    for i,data in enumerate(test_loader,0):\n","        model.eval()\n","        input_ids = data['ids'].to(device)\n","        attention_mask = data['mask'].to(device)\n","        labels = data['targets'].to(device)\n","        outputs = model(input_ids,attention_mask)\n","        acc += accuracy(outputs,labels)\n","print(i)\n","acc/((i+1)*16)"],"id":"9f735122","execution_count":19,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["61\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.9425403225806451"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"qIfELmG6fOAf","executionInfo":{"status":"ok","timestamp":1627836138471,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sachidanand V S ep19b010","photoUrl":"","userId":"00473899269515277127"}}},"source":[""],"id":"qIfELmG6fOAf","execution_count":19,"outputs":[]}]}